# ç¥ç»-ç¬¦å·æ··åˆåˆ†å¸ƒå¼çŸ¥è¯†ä¸“å®¶é—®ç­”ç³»ç»Ÿ

## é¡¹ç›®éœ€æ±‚æ–‡æ¡£ (NeuroSymbolic Expert QA - NSEQA)

---

## ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒç†å¿µ](#æ ¸å¿ƒç†å¿µ)
2. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
3. [ç³»ç»Ÿæ¶æ„è®¾è®¡](#ç³»ç»Ÿæ¶æ„è®¾è®¡)
4. [æ¨¡å—è¯¦ç»†è®¾è®¡](#æ¨¡å—è¯¦ç»†è®¾è®¡)
5. [æŠ€æœ¯å®ç°è¦ç‚¹](#æŠ€æœ¯å®ç°è¦ç‚¹)
6. [ä¾èµ–å’Œç¯å¢ƒ](#ä¾èµ–å’Œç¯å¢ƒ)
7. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
8. [åˆ›æ–°ç‚¹æ€»ç»“](#åˆ›æ–°ç‚¹æ€»ç»“)

---

## æ ¸å¿ƒç†å¿µ

### 1. åˆ†å¸ƒå¼çŸ¥è¯†ä¸“å®¶ç³»ç»Ÿ (Distributed Knowledge Experts)

#### ğŸ¯ æ ¸å¿ƒæ€æƒ³

ä¼ ç»Ÿçš„å•ä¸€çŸ¥è¯†åº“æ–¹æ³•å°±åƒè®©ä¸€ä¸ªäººæŒæ¡æ‰€æœ‰é¢†åŸŸçš„çŸ¥è¯†â€”â€”æ•ˆç‡ä½ä¸”å®¹æ˜“æ··æ·†ã€‚è€Œåˆ†å¸ƒå¼çŸ¥è¯†ä¸“å®¶ç³»ç»Ÿçš„ç†å¿µæ˜¯ï¼š**å°†çŸ¥è¯†æŒ‰é¢†åŸŸåˆ†å‰²ï¼Œæ¯ä¸ªä¸“å®¶åªè´Ÿè´£è‡ªå·±æ“…é•¿çš„é¢†åŸŸï¼Œé€šè¿‡åä½œè§£å†³å¤æ‚é—®é¢˜**ã€‚

#### ğŸ’¡ å…³é”®æœºåˆ¶

```
ä¼ ç»Ÿæ–¹æ³•ï¼š
ç”¨æˆ·é—®é¢˜ â†’ å•ä¸€å¤§çŸ¥è¯†åº“ â†’ æ£€ç´¢ â†’ ç­”æ¡ˆ
é—®é¢˜ï¼šçŸ¥è¯†æ··æ‚ã€æ£€ç´¢æ•ˆç‡ä½ã€éš¾ä»¥é’ˆå¯¹æ€§ä¼˜åŒ–

åˆ†å¸ƒå¼ä¸“å®¶æ–¹æ³•ï¼š
                    â”Œâ†’ ä¸“å®¶A(äººç‰©é¢†åŸŸ) â”€â”
ç”¨æˆ·é—®é¢˜ â†’ è·¯ç”±å™¨ â”€â”¼â†’ ä¸“å®¶B(åœ°ç†é¢†åŸŸ) â”€â”¼â†’ ç»“æœèåˆ â†’ ç­”æ¡ˆ
                    â””â†’ ä¸“å®¶C(ç»„ç»‡é¢†åŸŸ) â”€â”˜
ä¼˜åŠ¿ï¼šä¸“ä¸šåŒ–ã€å¹¶è¡Œæ£€ç´¢ã€å¯ç‹¬ç«‹ä¼˜åŒ–
```

#### ğŸ”‘ ä¸‰ä¸ªå…³é”®ç»„ä»¶

**1. ä¸“å®¶è¯†åˆ« (Expert Identification)**
- **è‡ªåŠ¨ä»æ•°æ®é›†ä¸­å‘ç°é¢†åŸŸè¾¹ç•Œ**
- æ–¹æ³•ï¼š
  - åŸºäºå®ä½“ç±»å‹èšç±»ï¼ˆäººç‰©ã€åœ°ç‚¹ã€ç»„ç»‡ã€äº‹ä»¶ç­‰ï¼‰
  - åŸºäºä¸»é¢˜æ¨¡å‹ï¼ˆLDAã€NMFï¼‰å‘ç°æ½œåœ¨ä¸»é¢˜
  - åŸºäºçŸ¥è¯†å›¾è°±ç¤¾åŒºæ£€æµ‹ï¼ˆç›¸å…³å®ä½“è‡ªç„¶èšé›†ï¼‰

**ç¤ºä¾‹**ï¼š
```python
# ä»2WikiMultihopQAæ•°æ®é›†è‡ªåŠ¨è¯†åˆ«å‡ºï¼š
Expert_0: äººç‰©é¢†åŸŸ
  - å®ä½“ç±»å‹: Person, Actor, Politician, Athlete
  - å…³é”®è¯: born, died, career, award, education
  - æ•°æ®é‡: 15,234æ¡

Expert_1: åœ°ç†é¢†åŸŸ  
  - å®ä½“ç±»å‹: City, Country, Landmark, Region
  - å…³é”®è¯: located, capital, population, area
  - æ•°æ®é‡: 8,756æ¡

Expert_2: ç»„ç»‡é¢†åŸŸ
  - å®ä½“ç±»å‹: Company, University, Government
  - å…³é”®è¯: founded, headquarters, CEO, revenue
  - æ•°æ®é‡: 12,443æ¡
```

**2. æ™ºèƒ½è·¯ç”± (Expert Routing)**
- **å°†é—®é¢˜è·¯ç”±åˆ°æœ€ç›¸å…³çš„ä¸“å®¶**
- ç­–ç•¥ï¼š
  - åŸºäºé—®é¢˜ä¸ä¸“å®¶é¢†åŸŸçš„è¯­ä¹‰ç›¸ä¼¼åº¦
  - åŸºäºå®ä½“è¯†åˆ«ï¼ˆé—®é¢˜ä¸­æåˆ°çš„å®ä½“å±äºå“ªä¸ªé¢†åŸŸï¼‰
  - åŸºäºå°æ¨¡å‹é¢„æµ‹ï¼ˆè®­ç»ƒä¸€ä¸ªè·¯ç”±åˆ†ç±»å™¨ï¼‰

**ç¤ºä¾‹**ï¼š
```python
é—®é¢˜: "ç‰¹æ–¯æ‹‰çš„CEOæ¯•ä¸šäºå“ªæ‰€å¤§å­¦ï¼Ÿ"

è·¯ç”±åˆ†æ:
- æåˆ°"ç‰¹æ–¯æ‹‰" â†’ ç»„ç»‡ä¸“å®¶(Expert_2) [ç›¸å…³åº¦: 0.9]
- æåˆ°"CEO" â†’ äººç‰©ä¸“å®¶(Expert_0) [ç›¸å…³åº¦: 0.8]  
- æåˆ°"å¤§å­¦" â†’ ç»„ç»‡ä¸“å®¶(Expert_2) [ç›¸å…³åº¦: 0.7]

è·¯ç”±å†³ç­–: ä¸»è¦æŸ¥è¯¢ Expert_2 å’Œ Expert_0
```

**3. åä½œæ¨ç† (Collaborative Reasoning)**
- **å¤šä¸ªä¸“å®¶ååŒè§£å†³å¤šè·³é—®é¢˜**
- åœºæ™¯ï¼š
  - å•è·³é—®é¢˜ï¼šä¸€ä¸ªä¸“å®¶å°±èƒ½å›ç­”
  - å¤šè·³é—®é¢˜ï¼šéœ€è¦å¤šä¸ªä¸“å®¶æ¥åŠ›
  - æ¯”è¾ƒé—®é¢˜ï¼šéœ€è¦å¤šä¸ªä¸“å®¶å¹¶è¡ŒæŸ¥è¯¢åå¯¹æ¯”

**ç¤ºä¾‹ï¼ˆå¤šè·³åä½œï¼‰**ï¼š
```python
é—®é¢˜: "ã€Šç›—æ¢¦ç©ºé—´ã€‹å¯¼æ¼”çš„å‡ºç”Ÿåœ°åœ¨å“ªä¸ªå›½å®¶ï¼Ÿ"

ç¬¬ä¸€è·³: [å½±è§†ä¸“å®¶]
  æŸ¥è¯¢: "ã€Šç›—æ¢¦ç©ºé—´ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ"
  ç»“æœ: Christopher Nolan
  
ç¬¬äºŒè·³: [äººç‰©ä¸“å®¶]  
  æŸ¥è¯¢: "Christopher Nolançš„å‡ºç”Ÿåœ°ï¼Ÿ"
  ç»“æœ: Westminster, London
  
ç¬¬ä¸‰è·³: [åœ°ç†ä¸“å®¶]
  æŸ¥è¯¢: "Westminster, Londonåœ¨å“ªä¸ªå›½å®¶ï¼Ÿ"
  ç»“æœ: United Kingdom

æœ€ç»ˆç­”æ¡ˆ: è‹±å›½
```

#### âœ¨ æ ¸å¿ƒä¼˜åŠ¿

1. **ä¸“ä¸šåŒ–**: æ¯ä¸ªä¸“å®¶ä¸“æ³¨è‡ªå·±çš„é¢†åŸŸï¼Œæ£€ç´¢æ›´ç²¾å‡†
2. **å¯æ‰©å±•**: æ–°å¢é¢†åŸŸåªéœ€æ·»åŠ æ–°ä¸“å®¶ï¼Œä¸å½±å“ç°æœ‰ç³»ç»Ÿ
3. **å¹¶è¡ŒåŒ–**: å¤šä¸ªä¸“å®¶å¯ä»¥åŒæ—¶æ£€ç´¢ï¼Œé™ä½å»¶è¿Ÿ
4. **å¯è§£é‡Š**: èƒ½è¿½æº¯æ¯ä¸ªç­”æ¡ˆæ¥è‡ªå“ªä¸ªä¸“å®¶
5. **å¯ä¼˜åŒ–**: æ¯ä¸ªä¸“å®¶å¯ä»¥ç‹¬ç«‹ä¼˜åŒ–ï¼ˆä¸åŒçš„ç´¢å¼•ç­–ç•¥ã€ä¸åŒçš„æ¨¡å‹ï¼‰

---

### 2. ç¥ç»-ç¬¦å·æ··åˆæ¶æ„ (Neuro-Symbolic Integration)

#### ğŸ¯ æ ¸å¿ƒæ€æƒ³

**ç¥ç»ç½‘ç»œæ“…é•¿"ç†è§£"ï¼Œç¬¦å·ç³»ç»Ÿæ“…é•¿"æ¨ç†"**ã€‚å°†ä¸¤è€…ç»“åˆï¼Œè®©AIæ—¢èƒ½ç†è§£è‡ªç„¶è¯­è¨€ï¼Œåˆèƒ½è¿›è¡Œç²¾ç¡®çš„é€»è¾‘æ¨ç†å’Œè®¡ç®—ã€‚

#### ğŸ’¡ ä¸ºä»€ä¹ˆéœ€è¦æ··åˆï¼Ÿ

**çº¯ç¥ç»ç½‘ç»œçš„å±€é™**ï¼š
```python
é—®é¢˜: "å¦‚æœä¸€ä¸ªæ•°æ˜¯36çš„å› æ•°ï¼ŒåŒæ—¶ä¹Ÿæ˜¯48çš„å› æ•°ï¼Œè¿™ä¸ªæ•°æœ€å¤§æ˜¯å¤šå°‘ï¼Ÿ"

GPT-4å¯èƒ½å›ç­”: "12" âœ“ (æ­£ç¡®ï¼Œä½†å¯èƒ½æ˜¯è®°å¿†æˆ–è¿‘ä¼¼)
å°æ¨¡å‹å¯èƒ½å›ç­”: "24" âœ— (é”™è¯¯ï¼Œæ¨ç†èƒ½åŠ›ä¸è¶³)

é—®é¢˜: "è®¡ç®— (123 * 456) + (789 * 321) - 1000"
ç¥ç»ç½‘ç»œ: "çº¦ç­‰äº300,000" (è¿‘ä¼¼ï¼Œå¯èƒ½é”™è¯¯)
éœ€è¦: ç²¾ç¡®ç­”æ¡ˆ 309,437
```

**çº¯ç¬¦å·ç³»ç»Ÿçš„å±€é™**ï¼š
```python
è¾“å…¥: "ç‰¹æ–¯æ‹‰çš„é‚£ä½å¤§ä½¬è¯»çš„æ˜¯å®¾å·çš„å­¦æ ¡å§ï¼Ÿæ˜¯å“ªä¸ªå·æ¥ç€ï¼Ÿ"

ç¬¦å·ç³»ç»Ÿ: æ— æ³•ç†è§£"é‚£ä½å¤§ä½¬"æŒ‡ä»£è°ï¼Œ"å®¾å·çš„å­¦æ ¡"æ˜¯ä»€ä¹ˆ
éœ€è¦: è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›
```

#### ğŸ”‘ æ··åˆæ¶æ„çš„å·¥ä½œæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               è¾“å…¥: è‡ªç„¶è¯­è¨€é—®é¢˜                          â”‚
â”‚     "ç‰¹æ–¯æ‹‰CEOçš„æ¯æ ¡åœ¨å“ªä¸ªå·ï¼Ÿ"                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ã€ç¥ç»å±‚ã€‘é—®é¢˜ç†è§£ä¸è¯­ä¹‰è§£æ                              â”‚
â”‚                                                          â”‚
â”‚  ä»»åŠ¡:                                                   â”‚
â”‚  - è¯†åˆ«å®ä½“: "ç‰¹æ–¯æ‹‰", "CEO", "æ¯æ ¡", "å·"                â”‚
â”‚  - è¯†åˆ«å…³ç³»é“¾: CEOå…³ç³» â†’ æ•™è‚²å…³ç³» â†’ åœ°ç†å…³ç³»              â”‚
â”‚  - è¯†åˆ«é—®é¢˜ç±»å‹: å¤šè·³æŸ¥è¯¢ (3è·³)                           â”‚
â”‚                                                          â”‚
â”‚  è¾“å‡º: ç»“æ„åŒ–æŸ¥è¯¢è¡¨ç¤º                                     â”‚
â”‚  {                                                       â”‚
â”‚    "type": "multi_hop",                                  â”‚
â”‚    "hops": [                                             â”‚
â”‚      {"entity": "Tesla", "relation": "CEO", "target": "?person"},
â”‚      {"entity": "?person", "relation": "alma_mater", "target": "?school"},
â”‚      {"entity": "?school", "relation": "located_in", "target": "?state"}
â”‚    ]                                                     â”‚
â”‚  }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ã€è½¬æ¢å±‚ã€‘ç¥ç»è¡¨ç¤º â†’ ç¬¦å·è¡¨ç¤º                             â”‚
â”‚                                                          â”‚
â”‚  ç”Ÿæˆç¬¦å·æŸ¥è¯¢ (ç±»ä¼¼SPARQL/Cypher):                        â”‚
â”‚  MATCH (t:Company {name: "Tesla"})                       â”‚
â”‚        -[:CEO]->(p:Person)                               â”‚
â”‚        -[:ALMA_MATER]->(s:School)                        â”‚
â”‚        -[:LOCATED_IN]->(st:State)                        â”‚
â”‚  RETURN st.name                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ã€ç¬¦å·å±‚ã€‘ç²¾ç¡®æ¨ç†ä¸æŸ¥è¯¢æ‰§è¡Œ                              â”‚
â”‚                                                          â”‚
â”‚  åœ¨çŸ¥è¯†å›¾è°±ä¸Šæ‰§è¡Œ:                                        â”‚
â”‚  ç¬¬1è·³: Tesla --CEO--> Elon Musk                         â”‚
â”‚  ç¬¬2è·³: Elon Musk --ALMA_MATER--> University of Pennsylvania
â”‚  ç¬¬3è·³: UPenn --LOCATED_IN--> Pennsylvania               â”‚
â”‚                                                          â”‚
â”‚  æ¨ç†ç»“æœ: Pennsylvania (ç½®ä¿¡åº¦: 100%)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ã€ç¥ç»å±‚ã€‘ç»“æœè§£é‡Šä¸è‡ªç„¶è¯­è¨€ç”Ÿæˆ                          â”‚
â”‚                                                          â”‚
â”‚  è¾“å…¥: ç¬¦å·æ¨ç†ç»“æœ + æ¨ç†è·¯å¾„                            â”‚
â”‚  è¾“å‡º: "å®¾å¤•æ³•å°¼äºšå·ã€‚ç‰¹æ–¯æ‹‰çš„CEOæ˜¯Elon Muskï¼Œä»–æ¯•ä¸šäº      â”‚
â”‚         å®¾å¤•æ³•å°¼äºšå¤§å­¦ï¼Œè¯¥å¤§å­¦ä½äºå®¾å¤•æ³•å°¼äºšå·ã€‚"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ”§ å…³é”®æŠ€æœ¯ç»„ä»¶

**1. è¯­ä¹‰è§£æå™¨ (Semantic Parser)**
- **åŠŸèƒ½**: å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»“æ„åŒ–è¡¨ç¤º
- **æŠ€æœ¯**:
  - ä¾å­˜å¥æ³•åˆ†æ
  - å®ä½“å’Œå…³ç³»æŠ½å–
  - é—®é¢˜æ¨¡æ¿åŒ¹é…
  - å°æ¨¡å‹ç”Ÿæˆç»“æ„åŒ–è¾“å‡º

**ç¤ºä¾‹**ï¼š
```python
è¾“å…¥: "è°æ˜¯ç°ä»»ç¾å›½æ€»ç»Ÿçš„å‰ä»»ï¼Ÿ"

è§£æè¾“å‡º:
{
  "entities": ["ç¾å›½", "æ€»ç»Ÿ"],
  "relations": ["ç°ä»»", "å‰ä»»"],
  "query_template": "PREV(CURRENT(President of USA))",
  "execution_plan": [
    "step1: æŸ¥è¯¢å½“å‰ç¾å›½æ€»ç»Ÿ",
    "step2: æŸ¥è¯¢è¯¥æ€»ç»Ÿçš„å‰ä»»"
  ]
}
```

**2. ç¬¦å·æ¨ç†å¼•æ“ (Symbolic Reasoner)**
- **åŠŸèƒ½**: åœ¨çŸ¥è¯†å›¾è°±ä¸Šæ‰§è¡Œç²¾ç¡®æŸ¥è¯¢
- **æ”¯æŒçš„æ¨ç†**:
  - è·¯å¾„æŸ¥è¯¢ï¼ˆå¤šè·³ï¼‰
  - é€»è¾‘æ¨ç†ï¼ˆæ¼”ç»ã€å½’çº³ï¼‰
  - æ•°å€¼è®¡ç®—
  - æ—¶é—´æ¨ç†

**ç¤ºä¾‹ï¼ˆé€»è¾‘æ¨ç†ï¼‰**ï¼š
```python
çŸ¥è¯†åº“:
  - æ‰€æœ‰å“ºä¹³åŠ¨ç‰©éœ€è¦å‘¼å¸ (âˆ€x: Mammal(x) â†’ NeedsBreathe(x))
  - é²¸é±¼æ˜¯å“ºä¹³åŠ¨ç‰© (Mammal(Whale))

æŸ¥è¯¢: "é²¸é±¼éœ€è¦å‘¼å¸å—ï¼Ÿ"

ç¬¦å·æ¨ç†:
  1. Mammal(Whale) â† å·²çŸ¥äº‹å®
  2. Mammal(Whale) â†’ NeedsBreathe(Whale) â† Modus Ponens
  3. âˆ´ NeedsBreathe(Whale) â† ç»“è®º
  
ç­”æ¡ˆ: æ˜¯çš„ (ç½®ä¿¡åº¦: 100%, å¯è§£é‡Š)
```

**ç¤ºä¾‹ï¼ˆæ•°å€¼è®¡ç®—ï¼‰**ï¼š
```python
é—®é¢˜: "å¦‚æœå°æ˜æœ‰5ä¸ªè‹¹æœï¼Œç»™äº†å°çº¢2ä¸ªï¼Œåˆä¹°äº†3ä¸ªï¼Œç°åœ¨æœ‰å‡ ä¸ªï¼Ÿ"

ç¥ç»å±‚æå–:
  - åˆå§‹: 5
  - æ“ä½œ1: -2 (ç»™å‡º)
  - æ“ä½œ2: +3 (ä¹°å…¥)

ç¬¦å·è®¡ç®—:
  result = 5 - 2 + 3 = 6 (ç²¾ç¡®)

å¯¹æ¯”çº¯ç¥ç»:
  GPTå¯èƒ½è¾“å‡º: "6ä¸ª" (ä½†æœ‰æ¦‚ç‡ç®—é”™æˆ7æˆ–8)
```

**3. æ··åˆæ£€ç´¢ (Hybrid Retrieval)**
- **å‘é‡æ£€ç´¢** (ç¥ç»):
  - è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…
  - æ¨¡ç³ŠæŸ¥è¯¢
  - å¤„ç†åŒä¹‰è¯ã€æ”¹å†™
  
- **å›¾è°±æ£€ç´¢** (ç¬¦å·):
  - ç²¾ç¡®å…³ç³»æŸ¥è¯¢
  - å¤šè·³è·¯å¾„æŸ¥æ‰¾
  - ç»“æ„åŒ–æ¨ç†

**ç»“åˆç­–ç•¥**ï¼š
```python
é—®é¢˜: "ä¹”å¸ƒæ–¯åˆ›ç«‹çš„å…¬å¸æ€»éƒ¨åœ¨å“ªï¼Ÿ"

å‘é‡æ£€ç´¢:
  query_embedding = embed("ä¹”å¸ƒæ–¯åˆ›ç«‹çš„å…¬å¸æ€»éƒ¨åœ¨å“ª")
  results = [
    "è‹¹æœå…¬å¸ç”±å²è’‚å¤«Â·ä¹”å¸ƒæ–¯ç­‰äººåˆ›ç«‹...",  # ç›¸å…³åº¦: 0.89
    "ä¹”å¸ƒæ–¯åœ¨è½¦åº“é‡Œåˆ›ç«‹äº†è‹¹æœ...",        # ç›¸å…³åº¦: 0.85
    "è‹¹æœæ€»éƒ¨ä½äºåŠ å·åº“æ¯”è’‚è¯º..."        # ç›¸å…³åº¦: 0.72
  ]

å›¾è°±æ£€ç´¢:
  æŸ¥è¯¢è·¯å¾„: ä¹”å¸ƒæ–¯ --åˆ›ç«‹--> è‹¹æœå…¬å¸ --æ€»éƒ¨--> ?åœ°ç‚¹
  ç²¾ç¡®ç»“æœ: Cupertino, California

èåˆ:
  - å‘é‡æ£€ç´¢æä¾›ä¸Šä¸‹æ–‡ç†è§£
  - å›¾è°±æ£€ç´¢æä¾›ç²¾ç¡®ç­”æ¡ˆ
  - äº¤å‰éªŒè¯æé«˜å‡†ç¡®åº¦
```

#### âœ¨ æ··åˆæ¶æ„çš„ä¼˜åŠ¿

| ç»´åº¦ | çº¯ç¥ç» | çº¯ç¬¦å· | ç¥ç»-ç¬¦å·æ··åˆ |
|------|--------|--------|--------------|
| **è‡ªç„¶è¯­è¨€ç†è§£** | âœ… å¼º | âŒ å¼± | âœ… å¼º |
| **é€»è¾‘æ¨ç†** | âš ï¸ ä¸ç¨³å®š | âœ… ç²¾ç¡® | âœ… ç²¾ç¡® |
| **æ•°å€¼è®¡ç®—** | âŒ æ˜“é”™ | âœ… 100%å‡†ç¡® | âœ… 100%å‡†ç¡® |
| **çµæ´»æ€§** | âœ… é«˜ | âŒ åƒµåŒ– | âœ… é«˜ |
| **å¯è§£é‡Šæ€§** | âŒ é»‘ç›’ | âœ… é€æ˜ | âœ… é€æ˜ |
| **çŸ¥è¯†æ›´æ–°** | âŒ éœ€é‡è®­ç»ƒ | âœ… ç›´æ¥ä¿®æ”¹ | âœ… ç›´æ¥ä¿®æ”¹ |

#### ğŸ¯ æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨

**ç»“åˆåˆ†å¸ƒå¼ä¸“å®¶çš„æ··åˆæ¶æ„**ï¼š

```
é—®é¢˜: "æ¯”è¾ƒè‹¹æœå’Œå¾®è½¯2023å¹´Q4è¥æ”¶ï¼Œå“ªå®¶æ›´é«˜ï¼Œé«˜å¤šå°‘ï¼Ÿ"

â”Œâ”€ ç¥ç»å±‚ï¼šç†è§£é—®é¢˜
â”‚  - è¯†åˆ«: æ¯”è¾ƒç±»é—®é¢˜
â”‚  - å®ä½“: Apple, Microsoft  
â”‚  - æŒ‡æ ‡: Revenue, Q4 2023
â”‚  - æ“ä½œ: æ¯”è¾ƒã€è®¡ç®—å·®å€¼
â”‚
â”œâ”€ è·¯ç”±å±‚ï¼šé€‰æ‹©ä¸“å®¶
â”‚  - è·¯ç”±åˆ° [è´¢åŠ¡ä¸“å®¶] (ä¸¤å®¶å…¬å¸éƒ½éœ€è¦)
â”‚
â”œâ”€ å¹¶è¡Œæ£€ç´¢ï¼ˆç¥ç»+ç¬¦å·ï¼‰
â”‚  â”œâ”€ å‘é‡æ£€ç´¢: "Apple Q4 2023 revenue" 
â”‚  â”‚  ç»“æœ: "è‹¹æœå…¬å¸2023å¹´ç¬¬å››å­£åº¦è¥æ”¶1195äº¿ç¾å…ƒ..."
â”‚  â”‚
â”‚  â”œâ”€ å›¾è°±æŸ¥è¯¢: (Apple, Q4_2023, Revenue)
â”‚  â”‚  ç²¾ç¡®å€¼: 119.58 billion USD
â”‚  â”‚
â”‚  â”œâ”€ å‘é‡æ£€ç´¢: "Microsoft Q4 2023 revenue"
â”‚  â”‚  ç»“æœ: "å¾®è½¯2023è´¢å¹´ç¬¬å››å­£åº¦è¥æ”¶564äº¿ç¾å…ƒ..."  
â”‚  â”‚
â”‚  â””â”€ å›¾è°±æŸ¥è¯¢: (Microsoft, Q4_2023, Revenue)
â”‚     ç²¾ç¡®å€¼: 56.52 billion USD
â”‚
â”œâ”€ ç¬¦å·è®¡ç®—å±‚ï¼šç²¾ç¡®è®¡ç®—
â”‚  difference = 119.58 - 56.52 = 63.06 billion USD
â”‚  percentage = (63.06 / 56.52) * 100 = 111.6%
â”‚
â””â”€ ç¥ç»ç”Ÿæˆå±‚ï¼šè‡ªç„¶è¯­è¨€ç­”æ¡ˆ
   "è‹¹æœå…¬å¸çš„è¥æ”¶æ›´é«˜ã€‚2023å¹´ç¬¬å››å­£åº¦ï¼Œè‹¹æœè¥æ”¶ä¸º1195.8äº¿ç¾å…ƒï¼Œ
    å¾®è½¯ä¸º565.2äº¿ç¾å…ƒï¼Œè‹¹æœé«˜å‡º630.6äº¿ç¾å…ƒï¼Œçº¦ä¸ºå¾®è½¯çš„2.12å€ã€‚"
```

---

### 3. ä¸¤è€…ç»“åˆçš„ååŒæ•ˆåº”

#### ğŸ”„ å®Œæ•´å·¥ä½œæµç¨‹

```
          ç”¨æˆ·é—®é¢˜ (è‡ªç„¶è¯­è¨€)
                 â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ç¥ç»å±‚: é—®é¢˜ç†è§£             â”‚ â† å¤„ç†è‡ªç„¶è¯­è¨€
    â”‚  - å®ä½“è¯†åˆ«                  â”‚
    â”‚  - æ„å›¾ç†è§£                  â”‚
    â”‚  - é—®é¢˜åˆ†ç±»                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  è·¯ç”±å™¨: ä¸“å®¶é€‰æ‹©             â”‚ â† åˆ†å¸ƒå¼æ¶æ„
    â”‚  - é¢†åŸŸåŒ¹é…                  â”‚
    â”‚  - å¤šä¸“å®¶åè°ƒ                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  è½¬æ¢å±‚: ç¥ç»â†’ç¬¦å·            â”‚ â† æ··åˆæ¶æ„æ¡¥æ¢
    â”‚  - è¯­ä¹‰è§£æ                  â”‚
    â”‚  - æŸ¥è¯¢ç”Ÿæˆ                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ä¸“å®¶å±‚: å¹¶è¡Œæ£€ç´¢             â”‚ â† åˆ†å¸ƒå¼+æ··åˆ
    â”‚  â”œâ”€ ä¸“å®¶A: å‘é‡+å›¾è°±         â”‚
    â”‚  â”œâ”€ ä¸“å®¶B: å‘é‡+å›¾è°±         â”‚
    â”‚  â””â”€ ä¸“å®¶C: å‘é‡+å›¾è°±         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ç¬¦å·å±‚: ç²¾ç¡®æ¨ç†             â”‚ â† ç¬¦å·ç³»ç»Ÿ
    â”‚  - é€»è¾‘æ¨ç†                  â”‚
    â”‚  - æ•°å€¼è®¡ç®—                  â”‚
    â”‚  - è·¯å¾„æŸ¥è¯¢                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ç¥ç»å±‚: ç­”æ¡ˆç”Ÿæˆ             â”‚ â† è‡ªç„¶è¯­è¨€ç”Ÿæˆ
    â”‚  - ç»“æœæ•´åˆ                  â”‚
    â”‚  - è‡ªç„¶è¯­è¨€è½¬æ¢              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
          æœ€ç»ˆç­”æ¡ˆ (è‡ªç„¶è¯­è¨€ + æ¨ç†è·¯å¾„)
```

#### ğŸ’ª ååŒä¼˜åŠ¿

1. **ç²¾ç¡®æ€§** (ç¬¦å·) + **çµæ´»æ€§** (ç¥ç»)
   - ç¥ç»ç½‘ç»œç†è§£å„ç§è¡¨è¾¾æ–¹å¼
   - ç¬¦å·ç³»ç»Ÿä¿è¯æ¨ç†å‡†ç¡®

2. **ä¸“ä¸šåŒ–** (åˆ†å¸ƒå¼) + **æ™ºèƒ½åŒ–** (æ··åˆ)
   - æ¯ä¸ªä¸“å®¶æœ‰ä¸“ä¸šçš„å‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±
   - æ··åˆæ£€ç´¢åœ¨å„è‡ªé¢†åŸŸå†…æ›´ç²¾å‡†

3. **å¯æ‰©å±•** (åˆ†å¸ƒå¼) + **å¯è§£é‡Š** (ç¬¦å·)
   - æ–°é¢†åŸŸæ–°å¢ä¸“å®¶å³å¯
   - æ¨ç†è·¯å¾„æ¸…æ™°å¯è¿½æº¯

4. **é«˜æ•ˆ** (åˆ†å¸ƒå¼å¹¶è¡Œ) + **å‡†ç¡®** (ç¬¦å·éªŒè¯)
   - å¤šä¸“å®¶å¹¶è¡Œæ£€ç´¢
   - ç¬¦å·ç³»ç»Ÿäº¤å‰éªŒè¯

---

## é¡¹ç›®æ¦‚è¿°

**é¡¹ç›®åç§°**: NeuroSymbolic Expert QA (NSEQA)

**æ ¸å¿ƒç†å¿µ**: 
- ç»“åˆåˆ†å¸ƒå¼çŸ¥è¯†ä¸“å®¶ç³»ç»Ÿ(Distributed Knowledge Experts)
- èåˆç¥ç»-ç¬¦å·æ··åˆæ¶æ„(Neuro-Symbolic Integration)
- å®ç°å°æ¨¡å‹é€šè¿‡å¤–éƒ¨çŸ¥è¯†å¢å¼ºï¼Œåœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸Šè¶…è¶Šå¤§æ¨¡å‹

**æŠ€æœ¯ç›®æ ‡**:
1. è‡ªåŠ¨ä»æ•°æ®é›†è¯†åˆ«å¹¶æ„å»ºå¤šä¸ªé¢†åŸŸä¸“å®¶çŸ¥è¯†åº“
2. ç¥ç»ç½‘ç»œå¤„ç†è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆ
3. ç¬¦å·ç³»ç»Ÿå¤„ç†ç²¾ç¡®æ¨ç†å’ŒçŸ¥è¯†æ£€ç´¢
4. æ”¯æŒå¤æ‚çš„å¤šè·³æ¨ç†æŸ¥è¯¢
5. æ¨¡å—åŒ–ã€å¯æ‰©å±•ã€ä½è€¦åˆè®¾è®¡

---

## ç³»ç»Ÿæ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·æ¥å£å±‚                             â”‚
â”‚                  (CLI / API / Web)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  é—®ç­”æ¨ç†å¼•æ“ (QA Engine)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ é—®é¢˜ç†è§£æ¨¡å—  â”‚  â”‚ æ¨ç†åè°ƒå™¨   â”‚  â”‚ ç­”æ¡ˆç”Ÿæˆæ¨¡å—  â”‚  â”‚
â”‚  â”‚  (Neural)    â”‚  â”‚ (Meta-Agent) â”‚  â”‚  (Neural)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç¥ç»-ç¬¦å·è½¬æ¢å±‚ (N-S Bridge)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ è¯­ä¹‰è§£æå™¨    â”‚  â”‚ æŸ¥è¯¢ç”Ÿæˆå™¨   â”‚  â”‚ ç»“æœè§£é‡Šå™¨   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            åˆ†å¸ƒå¼ä¸“å®¶çŸ¥è¯†åº“ (Expert Knowledge Bases)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ä¸“å®¶åº“ 1  â”‚ â”‚ ä¸“å®¶åº“ 2  â”‚ â”‚ ä¸“å®¶åº“ 3  â”‚ â”‚  ...     â”‚  â”‚
â”‚  â”‚ (å‘é‡+å›¾) â”‚ â”‚ (å‘é‡+å›¾) â”‚ â”‚ (å‘é‡+å›¾) â”‚ â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              çŸ¥è¯†åº“æ„å»ºç³»ç»Ÿ (KB Builder)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æ•°æ®åŠ è½½å™¨    â”‚  â”‚ ä¸“å®¶è¯†åˆ«å™¨   â”‚  â”‚ ç´¢å¼•æ„å»ºå™¨   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ¨¡å—è¯¦ç»†è®¾è®¡

### Module 1: æ•°æ®å±‚ (Data Layer)

**ç›®å½•ç»“æ„**:
```
data/
â”œâ”€â”€ raw/                    # åŸå§‹æ•°æ®é›†
â”‚   â”œâ”€â”€ 2wikimultihopqa/
â”‚   â””â”€â”€ musique/
â”œâ”€â”€ processed/              # å¤„ç†åçš„æ•°æ®
â”‚   â”œâ”€â”€ entities.json
â”‚   â”œâ”€â”€ relations.json
â”‚   â””â”€â”€ expert_domains.json
â””â”€â”€ knowledge_bases/        # ä¸“å®¶çŸ¥è¯†åº“å­˜å‚¨
    â”œâ”€â”€ expert_0/
    â”‚   â”œâ”€â”€ vectors.pkl     # å‘é‡ç´¢å¼•
    â”‚   â”œâ”€â”€ graph.pkl       # çŸ¥è¯†å›¾è°±
    â”‚   â””â”€â”€ metadata.json   # å…ƒæ•°æ®
    â”œâ”€â”€ expert_1/
    â””â”€â”€ ...
```

**åŠŸèƒ½éœ€æ±‚**:

1. **æ•°æ®åŠ è½½å™¨ (`data/loader.py`)**
   ```python
   class DatasetLoader:
       """åŠ è½½2WikiMultihopQAå’ŒMuSiQueæ•°æ®é›†"""
       
       def load_2wiki(self, path: str) -> List[Dict]
       def load_musique(self, path: str) -> List[Dict]
       def parse_question(self, item: Dict) -> Question
       def extract_entities(self, item: Dict) -> List[Entity]
       def extract_relations(self, item: Dict) -> List[Relation]
   ```

2. **æ•°æ®é¢„å¤„ç†å™¨ (`data/preprocessor.py`)**
   ```python
   class DataPreprocessor:
       """é¢„å¤„ç†æ•°æ®ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯"""
       
       def clean_text(self, text: str) -> str
       def extract_supporting_facts(self, item: Dict) -> List[Fact]
       def build_reasoning_chain(self, item: Dict) -> ReasoningChain
       def identify_question_type(self, question: str) -> QuestionType
   ```

**æ•°æ®æ¨¡å‹**:
```python
# data/models.py

@dataclass
class Entity:
    id: str
    name: str
    type: str  # person, location, organization, etc.
    attributes: Dict[str, Any]

@dataclass
class Relation:
    subject: str
    predicate: str
    object: str
    confidence: float

@dataclass
class Question:
    id: str
    text: str
    question_type: str  # single_hop, multi_hop, comparison, etc.
    answer: str
    supporting_facts: List[Fact]
    reasoning_hops: int

@dataclass
class Fact:
    text: str
    entities: List[str]
    relations: List[Relation]
```

---

### Module 2: çŸ¥è¯†åº“æ„å»ºç³»ç»Ÿ (KB Builder)

**ç›®å½•ç»“æ„**:
```
kb_builder/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ expert_identifier.py    # è‡ªåŠ¨è¯†åˆ«ä¸“å®¶é¢†åŸŸ
â”œâ”€â”€ vector_builder.py       # æ„å»ºå‘é‡ç´¢å¼•
â”œâ”€â”€ graph_builder.py        # æ„å»ºçŸ¥è¯†å›¾è°±
â””â”€â”€ indexer.py              # ç»Ÿä¸€ç´¢å¼•æ¥å£
```

**æ ¸å¿ƒåŠŸèƒ½**:

1. **ä¸“å®¶é¢†åŸŸè¯†åˆ«å™¨ (`kb_builder/expert_identifier.py`)**
   ```python
   class ExpertIdentifier:
       """è‡ªåŠ¨ä»æ•°æ®é›†è¯†åˆ«ä¸“å®¶é¢†åŸŸ"""
       
       def __init__(self, n_experts: int = None, method: str = 'clustering'):
           """
           Args:
               n_experts: ä¸“å®¶æ•°é‡ï¼ŒNoneåˆ™è‡ªåŠ¨ç¡®å®š
               method: è¯†åˆ«æ–¹æ³• - 'clustering', 'lda', 'entity_based'
           """
       
       def identify_domains(self, dataset: List[Dict]) -> List[ExpertDomain]:
           """
           è¯†åˆ«æ•°æ®é›†ä¸­çš„ä¸“å®¶é¢†åŸŸ
           
           æ–¹æ³•ï¼š
           1. åŸºäºå®ä½“ç±»å‹èšç±»ï¼ˆäººç‰©ã€åœ°ç‚¹ã€ç»„ç»‡ç­‰ï¼‰
           2. åŸºäºä¸»é¢˜æ¨¡å‹ï¼ˆLDAï¼‰
           3. åŸºäºçŸ¥è¯†å›¾è°±ç¤¾åŒºæ£€æµ‹
           
           Returns:
               List[ExpertDomain]: è¯†åˆ«å‡ºçš„ä¸“å®¶é¢†åŸŸåˆ—è¡¨
           """
       
       def assign_data_to_experts(self, 
                                  dataset: List[Dict], 
                                  domains: List[ExpertDomain]) -> Dict[str, List[Dict]]:
           """å°†æ•°æ®åˆ†é…ç»™ä¸åŒçš„ä¸“å®¶åº“"""
   ```

2. **å‘é‡ç´¢å¼•æ„å»ºå™¨ (`kb_builder/vector_builder.py`)**
   ```python
   class VectorIndexBuilder:
       """æ„å»ºå‘é‡æ£€ç´¢ç´¢å¼•"""
       
       def __init__(self, 
                    embedding_model: str = 'sentence-transformers/all-MiniLM-L6-v2',
                    index_type: str = 'faiss'):
           """
           Args:
               embedding_model: ä½¿ç”¨çš„embeddingæ¨¡å‹
               index_type: ç´¢å¼•ç±»å‹ - 'faiss', 'annoy', 'simple'
           """
       
       def build_index(self, 
                      documents: List[str], 
                      metadata: List[Dict]) -> VectorIndex:
           """
           æ„å»ºå‘é‡ç´¢å¼•
           
           Steps:
           1. æ–‡æœ¬å‘é‡åŒ–
           2. æ„å»ºFAISSç´¢å¼•ï¼ˆæ”¯æŒå¿«é€Ÿç›¸ä¼¼åº¦æœç´¢ï¼‰
           3. ä¿å­˜å…ƒæ•°æ®æ˜ å°„
           """
       
       def save_index(self, index: VectorIndex, path: str):
           """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶"""
       
       def load_index(self, path: str) -> VectorIndex:
           """ä»æ–‡ä»¶åŠ è½½ç´¢å¼•"""
   ```

3. **çŸ¥è¯†å›¾è°±æ„å»ºå™¨ (`kb_builder/graph_builder.py`)**
   ```python
   class KnowledgeGraphBuilder:
       """æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆç¬¦å·è¡¨ç¤ºï¼‰"""
       
       def build_graph(self, 
                      entities: List[Entity], 
                      relations: List[Relation]) -> KnowledgeGraph:
           """
           æ„å»ºçŸ¥è¯†å›¾è°±
           
           ç»“æ„ï¼š
           - èŠ‚ç‚¹ï¼šå®ä½“ï¼ˆEntityï¼‰
           - è¾¹ï¼šå…³ç³»ï¼ˆRelationï¼‰
           - æ”¯æŒå¤šè·³è·¯å¾„æŸ¥è¯¢
           """
       
       def add_entity(self, graph: KnowledgeGraph, entity: Entity):
           """æ·»åŠ å®ä½“èŠ‚ç‚¹"""
       
       def add_relation(self, graph: KnowledgeGraph, relation: Relation):
           """æ·»åŠ å…³ç³»è¾¹"""
       
       def save_graph(self, graph: KnowledgeGraph, path: str):
           """ä¿å­˜å›¾è°±ï¼ˆä½¿ç”¨pickleæˆ–NetworkXæ ¼å¼ï¼‰"""
       
       def load_graph(self, path: str) -> KnowledgeGraph:
           """åŠ è½½å›¾è°±"""
   ```

**ä¸“å®¶é¢†åŸŸæ¨¡å‹**:
```python
# kb_builder/models.py

@dataclass
class ExpertDomain:
    id: str
    name: str
    description: str
    entity_types: List[str]  # è¯¥ä¸“å®¶æ“…é•¿çš„å®ä½“ç±»å‹
    keywords: List[str]       # é¢†åŸŸå…³é”®è¯
    data_count: int           # æ•°æ®é‡

class VectorIndex:
    """å‘é‡ç´¢å¼•å°è£…"""
    def __init__(self):
        self.index = None      # FAISS index
        self.embeddings = []   # å‘é‡
        self.metadata = []     # å…ƒæ•°æ®
    
    def search(self, query_vector: np.ndarray, top_k: int = 5) -> List[SearchResult]

class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°±å°è£…ï¼ˆåŸºäºNetworkXï¼‰"""
    def __init__(self):
        self.graph = nx.MultiDiGraph()
    
    def query_path(self, start: str, end: str, max_hops: int = 3) -> List[Path]
    def query_neighbors(self, entity: str, relation_type: str = None) -> List[Entity]
    def subgraph(self, entities: List[str]) -> KnowledgeGraph
```

---

### Module 3: åˆ†å¸ƒå¼ä¸“å®¶çŸ¥è¯†åº“ (Expert Knowledge Bases)

**ç›®å½•ç»“æ„**:
```
experts/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base_expert.py          # ä¸“å®¶åŸºç±»
â”œâ”€â”€ expert_router.py        # ä¸“å®¶è·¯ç”±å™¨
â””â”€â”€ retriever.py            # æ£€ç´¢å™¨
```

**æ ¸å¿ƒåŠŸèƒ½**:

1. **ä¸“å®¶åŸºç±» (`experts/base_expert.py`)**
   ```python
   class BaseExpert(ABC):
       """ä¸“å®¶çŸ¥è¯†åº“åŸºç±»"""
       
       def __init__(self, expert_id: str, domain: ExpertDomain, kb_path: str):
           self.expert_id = expert_id
           self.domain = domain
           self.vector_index = self.load_vector_index(kb_path)
           self.knowledge_graph = self.load_knowledge_graph(kb_path)
       
       @abstractmethod
       def retrieve_vector(self, query: str, top_k: int = 5) -> List[Document]:
           """å‘é‡æ£€ç´¢ï¼ˆç¥ç»æ–¹æ³•ï¼‰"""
       
       @abstractmethod
       def retrieve_symbolic(self, query: Dict) -> List[Result]:
           """ç¬¦å·æ£€ç´¢ï¼ˆå›¾è°±æŸ¥è¯¢ï¼‰"""
       
       def hybrid_retrieve(self, query: str, symbolic_query: Dict = None) -> List[Result]:
           """æ··åˆæ£€ç´¢ï¼šç»“åˆå‘é‡å’Œç¬¦å·"""
           vector_results = self.retrieve_vector(query)
           if symbolic_query:
               symbolic_results = self.retrieve_symbolic(symbolic_query)
               # èåˆç»“æœ
               return self.merge_results(vector_results, symbolic_results)
           return vector_results
   ```

2. **ä¸“å®¶è·¯ç”±å™¨ (`experts/expert_router.py`)**
   ```python
   class ExpertRouter:
       """å†³å®šæŸ¥è¯¢åº”è¯¥è·¯ç”±åˆ°å“ªä¸ª/å“ªäº›ä¸“å®¶"""
       
       def __init__(self, experts: List[BaseExpert], routing_model: str = 'similarity'):
           self.experts = experts
           self.routing_model = routing_model
       
       def route(self, query: str, top_k_experts: int = 2) -> List[BaseExpert]:
           """
           è·¯ç”±ç­–ç•¥ï¼š
           1. åŸºäºæŸ¥è¯¢ä¸ä¸“å®¶é¢†åŸŸçš„ç›¸ä¼¼åº¦
           2. åŸºäºå°æ¨¡å‹é¢„æµ‹
           3. åŸºäºè§„åˆ™åŒ¹é…
           
           Returns:
               æœ€ç›¸å…³çš„top_kä¸ªä¸“å®¶
           """
       
       def route_multi_hop(self, 
                          query: str, 
                          reasoning_chain: List[str]) -> List[List[BaseExpert]]:
           """
           å¤šè·³æŸ¥è¯¢è·¯ç”±
           ä¸ºæ¨ç†é“¾çš„æ¯ä¸€è·³åˆ†é…ä¸“å®¶
           """
   ```

3. **æ£€ç´¢å™¨ (`experts/retriever.py`)**
   ```python
   class HybridRetriever:
       """æ··åˆæ£€ç´¢å™¨ï¼šç¥ç»+ç¬¦å·"""
       
       def retrieve(self, 
                   query: str,
                   experts: List[BaseExpert],
                   retrieval_mode: str = 'hybrid') -> List[RetrievalResult]:
           """
           Args:
               retrieval_mode: 'vector', 'symbolic', 'hybrid'
           
           Returns:
               æ£€ç´¢ç»“æœï¼ŒåŒ…å«æ¥æºä¸“å®¶ä¿¡æ¯
           """
       
       def rerank(self, results: List[RetrievalResult], query: str) -> List[RetrievalResult]:
           """é‡æ’åºæ£€ç´¢ç»“æœ"""
   ```

---

### Module 4: ç¥ç»-ç¬¦å·è½¬æ¢å±‚ (Neuro-Symbolic Bridge)

**ç›®å½•ç»“æ„**:
```
neuro_symbolic/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ semantic_parser.py      # è¯­ä¹‰è§£æå™¨
â”œâ”€â”€ query_generator.py      # æŸ¥è¯¢ç”Ÿæˆå™¨
â””â”€â”€ result_interpreter.py   # ç»“æœè§£é‡Šå™¨
```

**æ ¸å¿ƒåŠŸèƒ½**:

1. **è¯­ä¹‰è§£æå™¨ (`neuro_symbolic/semantic_parser.py`)**
   ```python
   class SemanticParser:
       """å°†è‡ªç„¶è¯­è¨€é—®é¢˜è§£æä¸ºç»“æ„åŒ–è¡¨ç¤º"""
       
       def parse(self, question: str) -> StructuredQuery:
           """
           è§£æé—®é¢˜ä¸ºç»“æ„åŒ–æŸ¥è¯¢
           
           è¾“å‡ºç¤ºä¾‹ï¼š
           {
               "query_type": "multi_hop",
               "hops": [
                   {
                       "hop_id": 1,
                       "intent": "find_entity",
                       "target": "CEO of Tesla",
                       "expected_type": "Person"
                   },
                   {
                       "hop_id": 2,
                       "intent": "find_attribute",
                       "target": "{result_from_hop_1}.university",
                       "expected_type": "Organization"
                   }
               ]
           }
           """
       
       def extract_entities(self, question: str) -> List[str]:
           """æå–é—®é¢˜ä¸­çš„å®ä½“"""
       
       def identify_relations(self, question: str) -> List[str]:
           """è¯†åˆ«é—®é¢˜ä¸­çš„å…³ç³»"""
   ```

2. **æŸ¥è¯¢ç”Ÿæˆå™¨ (`neuro_symbolic/query_generator.py`)**
   ```python
   class QueryGenerator:
       """å°†ç»“æ„åŒ–æŸ¥è¯¢è½¬æ¢ä¸ºç¬¦å·æŸ¥è¯¢ï¼ˆå›¾è°±æŸ¥è¯¢ï¼‰"""
       
       def generate_graph_query(self, structured_query: StructuredQuery) -> GraphQuery:
           """
           ç”ŸæˆçŸ¥è¯†å›¾è°±æŸ¥è¯¢
           
           è¾“å‡ºç¤ºä¾‹ï¼ˆç±»SPARQLï¼‰ï¼š
           {
               "pattern": [
                   ("Tesla", "CEO", "?person"),
                   ("?person", "graduated_from", "?university")
               ],
               "filters": [],
               "return": ["?university"]
           }
           """
       
       def generate_vector_query(self, structured_query: StructuredQuery) -> str:
           """ç”Ÿæˆå‘é‡æ£€ç´¢æŸ¥è¯¢ï¼ˆä¼˜åŒ–åçš„æŸ¥è¯¢æ–‡æœ¬ï¼‰"""
   ```

3. **ç»“æœè§£é‡Šå™¨ (`neuro_symbolic/result_interpreter.py`)**
   ```python
   class ResultInterpreter:
       """è§£é‡Šç¬¦å·ç³»ç»Ÿè¿”å›çš„ç»“æœ"""
       
       def interpret(self, 
                    symbolic_results: List[SymbolicResult],
                    original_question: str) -> InterpretedResult:
           """
           å°†ç¬¦å·ç»“æœè½¬æ¢ä¸ºå¯ç†è§£çš„å½¢å¼
           
           åŠŸèƒ½ï¼š
           1. æå–ç­”æ¡ˆå®ä½“
           2. æ„å»ºæ¨ç†è·¯å¾„
           3. è®¡ç®—ç½®ä¿¡åº¦
           """
       
       def explain_reasoning(self, results: List[SymbolicResult]) -> ReasoningExplanation:
           """ç”Ÿæˆæ¨ç†è¿‡ç¨‹è§£é‡Š"""
   ```

---

### Module 5: é—®ç­”æ¨ç†å¼•æ“ (QA Reasoning Engine)

**ç›®å½•ç»“æ„**:
```
qa_engine/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ question_understanding.py   # é—®é¢˜ç†è§£
â”œâ”€â”€ meta_reasoner.py            # å…ƒæ¨ç†å™¨
â”œâ”€â”€ multi_hop_reasoner.py       # å¤šè·³æ¨ç†
â””â”€â”€ answer_generator.py         # ç­”æ¡ˆç”Ÿæˆ
```

**æ ¸å¿ƒåŠŸèƒ½**:

1. **é—®é¢˜ç†è§£æ¨¡å— (`qa_engine/question_understanding.py`)**
   ```python
   class QuestionUnderstanding:
       """ç†è§£ç”¨æˆ·é—®é¢˜"""
       
       def analyze(self, question: str) -> QuestionAnalysis:
           """
           åˆ†æé—®é¢˜
           
           è¿”å›ï¼š
           - question_type: å•è·³/å¤šè·³/æ¯”è¾ƒ/è®¡æ•°ç­‰
           - complexity: å¤æ‚åº¦è¯„åˆ†
           - required_hops: é¢„ä¼°éœ€è¦çš„æ¨ç†è·³æ•°
           - key_entities: å…³é”®å®ä½“
           - relations: æ¶‰åŠçš„å…³ç³»
           """
   ```

2. **å…ƒæ¨ç†å™¨ (`qa_engine/meta_reasoner.py`)**
   ```python
   class MetaReasoner:
       """åè°ƒæ•´ä¸ªæ¨ç†è¿‡ç¨‹"""
       
       def __init__(self, 
                    expert_router: ExpertRouter,
                    semantic_parser: SemanticParser,
                    retriever: HybridRetriever):
           self.expert_router = expert_router
           self.semantic_parser = semantic_parser
           self.retriever = retriever
       
       def reason(self, question: str) -> ReasoningResult:
           """
           æ¨ç†æµç¨‹ï¼š
           1. ç†è§£é—®é¢˜
           2. åˆ¤æ–­æ˜¯å¦éœ€è¦å¤šè·³
           3. å¦‚æœå•è·³ï¼šç›´æ¥æ£€ç´¢+ç”Ÿæˆç­”æ¡ˆ
           4. å¦‚æœå¤šè·³ï¼šè°ƒç”¨å¤šè·³æ¨ç†å™¨
           """
       
       def plan_reasoning(self, question_analysis: QuestionAnalysis) -> ReasoningPlan:
           """è§„åˆ’æ¨ç†æ­¥éª¤"""
   ```

3. **å¤šè·³æ¨ç†å™¨ (`qa_engine/multi_hop_reasoner.py`)**
   ```python
   class MultiHopReasoner:
       """å¤„ç†å¤šè·³æ¨ç†"""
       
       def chain_reasoning(self, 
                          question: str,
                          max_hops: int = 5) -> ChainReasoningResult:
           """
           é“¾å¼æ¨ç†ï¼ˆæ–¹æ¡ˆä¸€ï¼‰
           
           æµç¨‹ï¼š
           1. ç¬¬ä¸€è·³ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸­é—´å®ä½“
           2. ç¬¬äºŒè·³ï¼šåŸºäºä¸­é—´å®ä½“ç»§ç»­æŸ¥è¯¢
           3. ...
           4. æœ€åä¸€è·³ï¼šå¾—åˆ°æœ€ç»ˆç­”æ¡ˆ
           
           æ¯ä¸€è·³ï¼š
           - é€‰æ‹©ä¸“å®¶
           - æ£€ç´¢ä¿¡æ¯
           - éªŒè¯ç»“æœ
           - å‡†å¤‡ä¸‹ä¸€è·³æŸ¥è¯¢
           """
       
       def graph_reasoning(self, 
                          question: str,
                          structured_query: StructuredQuery) -> GraphReasoningResult:
           """
           å›¾æ¨ç†ï¼ˆæ–¹æ¡ˆäºŒï¼‰
           
           æµç¨‹ï¼š
           1. å°†é—®é¢˜è½¬æ¢ä¸ºå›¾æŸ¥è¯¢æ¨¡å¼
           2. åœ¨çŸ¥è¯†å›¾è°±ä¸Šæ‰§è¡Œè·¯å¾„æŸ¥è¯¢
           3. è¿”å›æ‰€æœ‰æ»¡è¶³æ¡ä»¶çš„è·¯å¾„
           """
       
       def iterative_refinement(self, 
                               question: str,
                               max_iterations: int = 5) -> IterativeResult:
           """
           è¿­ä»£ç²¾ç‚¼ï¼ˆæ–¹æ¡ˆä¸‰ï¼‰
           
           æµç¨‹ï¼š
           1. åˆå§‹æ£€ç´¢
           2. å°æ¨¡å‹è¯„ä¼°ï¼šæ˜¯å¦è¶³å¤Ÿå›ç­”ï¼Ÿç¼ºä»€ä¹ˆä¿¡æ¯ï¼Ÿ
           3. å¦‚æœä¸å¤Ÿï¼šç”Ÿæˆè¡¥å……æŸ¥è¯¢
           4. é‡å¤ç›´åˆ°æœ‰ç­”æ¡ˆæˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
           """
   ```

4. **ç­”æ¡ˆç”Ÿæˆå™¨ (`qa_engine/answer_generator.py`)**
   ```python
   class AnswerGenerator:
       """åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€ç­”æ¡ˆ"""
       
       def generate(self, 
                   question: str,
                   retrieved_info: List[RetrievalResult],
                   reasoning_path: List[ReasoningStep] = None) -> Answer:
           """
           ç”Ÿæˆç­”æ¡ˆ
           
           æ¨¡å¼ï¼š
           1. å¦‚æœæœ‰æ˜ç¡®çš„ç¬¦å·ç»“æœ â†’ ç›´æ¥è¿”å›
           2. å¦‚æœéœ€è¦ç»¼åˆå¤šä¸ªæ¥æº â†’ ç”¨å°æ¨¡å‹ç”Ÿæˆ
           3. å¦‚æœéœ€è¦è®¡ç®— â†’ è°ƒç”¨ç¬¦å·è®¡ç®—æ¨¡å—
           
           åŒ…å«ï¼š
           - answer_text: ç­”æ¡ˆæ–‡æœ¬
           - confidence: ç½®ä¿¡åº¦
           - supporting_facts: æ”¯æ’‘äº‹å®
           - reasoning_explanation: æ¨ç†è§£é‡Š
           """
   ```

---

### Module 6: å·¥å…·å’Œè¾…åŠ©æ¨¡å—

**ç›®å½•ç»“æ„**:
```
utils/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ embeddings.py           # å‘é‡åŒ–å·¥å…·
â”œâ”€â”€ graph_utils.py          # å›¾æ“ä½œå·¥å…·
â”œâ”€â”€ metrics.py              # è¯„ä¼°æŒ‡æ ‡
â””â”€â”€ config.py               # é…ç½®ç®¡ç†
```

**é…ç½®ç®¡ç† (`utils/config.py`)**:
```yaml
# config.yaml ç¤ºä¾‹
system:
  n_experts: null  # nullè¡¨ç¤ºè‡ªåŠ¨è¯†åˆ«
  expert_identification_method: 'clustering'  # 'clustering', 'lda', 'entity_based'
  
models:
  embedding_model: 'sentence-transformers/all-MiniLM-L6-v2'
  small_language_model: 'google/flan-t5-base'  # ç”¨äºç†è§£å’Œç”Ÿæˆ
  
retrieval:
  vector_top_k: 5
  rerank: true
  hybrid_alpha: 0.7  # å‘é‡æ£€ç´¢æƒé‡
  
reasoning:
  max_hops: 5
  max_iterations: 3
  reasoning_mode: 'chain'  # 'chain', 'graph', 'iterative'
  
storage:
  kb_base_path: './data/knowledge_bases'
  cache_enabled: true
```

---

### Module 7: ä¸»æµç¨‹å’Œæ¥å£

**ç›®å½•ç»“æ„**:
```
main.py                     # ä¸»å…¥å£
pipeline/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ kb_build_pipeline.py    # çŸ¥è¯†åº“æ„å»ºæµç¨‹
â””â”€â”€ qa_pipeline.py          # é—®ç­”æµç¨‹
```

**çŸ¥è¯†åº“æ„å»ºæµç¨‹ (`pipeline/kb_build_pipeline.py`)**:
```python
class KBBuildPipeline:
    """çŸ¥è¯†åº“æ„å»ºå®Œæ•´æµç¨‹"""
    
    def run(self, dataset_path: str, dataset_type: str = '2wiki'):
        """
        å®Œæ•´æµç¨‹ï¼š
        1. åŠ è½½æ•°æ®é›†
        2. é¢„å¤„ç†æ•°æ®
        3. è¯†åˆ«ä¸“å®¶é¢†åŸŸ
        4. ä¸ºæ¯ä¸ªä¸“å®¶æ„å»ºå‘é‡ç´¢å¼•
        5. ä¸ºæ¯ä¸ªä¸“å®¶æ„å»ºçŸ¥è¯†å›¾è°±
        6. ä¿å­˜æ‰€æœ‰ç´¢å¼•å’Œå…ƒæ•°æ®
        
        è¾“å‡ºï¼š
        - data/knowledge_bases/expert_0/...
        - data/knowledge_bases/expert_1/...
        - ...
        """
```

**é—®ç­”æµç¨‹ (`pipeline/qa_pipeline.py`)**:
```python
class QAPipeline:
    """é—®ç­”å®Œæ•´æµç¨‹"""
    
    def __init__(self, kb_path: str):
        # åŠ è½½æ‰€æœ‰ä¸“å®¶
        self.experts = self.load_experts(kb_path)
        self.expert_router = ExpertRouter(self.experts)
        self.meta_reasoner = MetaReasoner(...)
        self.answer_generator = AnswerGenerator(...)
    
    def answer(self, question: str) -> Answer:
        """
        å®Œæ•´é—®ç­”æµç¨‹ï¼š
        1. é—®é¢˜ç†è§£
        2. å…ƒæ¨ç†è§„åˆ’
        3. ä¸“å®¶è·¯ç”±
        4. æ£€ç´¢ï¼ˆå‘é‡+ç¬¦å·ï¼‰
        5. å¤šè·³æ¨ç†ï¼ˆå¦‚éœ€è¦ï¼‰
        6. ç­”æ¡ˆç”Ÿæˆ
        7. è¿”å›ç»“æœ+è§£é‡Š
        """
```

**ä¸»å…¥å£ (`main.py`)**:
```python
import argparse

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', choices=['build', 'query', 'eval'], required=True)
    parser.add_argument('--dataset', type=str, help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--question', type=str, help='é—®é¢˜æ–‡æœ¬')
    parser.add_argument('--config', default='config.yaml')
    
    args = parser.parse_args()
    
    if args.mode == 'build':
        # æ„å»ºçŸ¥è¯†åº“
        pipeline = KBBuildPipeline(config=args.config)
        pipeline.run(args.dataset)
    
    elif args.mode == 'query':
        # å›ç­”é—®é¢˜
        qa_pipeline = QAPipeline(kb_path='./data/knowledge_bases')
        answer = qa_pipeline.answer(args.question)
        print(f"Answer: {answer.text}")
        print(f"Confidence: {answer.confidence}")
        print(f"Reasoning: {answer.explanation}")
    
    elif args.mode == 'eval':
        # è¯„ä¼°ç³»ç»Ÿ
        evaluator = Evaluator(qa_pipeline)
        results = evaluator.evaluate(args.dataset)
        print(results)

if __name__ == '__main__':
    main()
```

---

## è¯„ä¼°æ¨¡å—

**ç›®å½•ç»“æ„**:
```
evaluation/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ evaluator.py            # è¯„ä¼°å™¨
â””â”€â”€ metrics.py              # è¯„ä¼°æŒ‡æ ‡
```

**è¯„ä¼°å™¨ (`evaluation/evaluator.py`)**:
```python
class Evaluator:
    """ç³»ç»Ÿè¯„ä¼°"""
    
    def evaluate(self, test_dataset: List[Dict]) -> EvaluationResults:
        """
        è¯„ä¼°æŒ‡æ ‡ï¼š
        1. Exact Match (EM)
        2. F1 Score
        3. Answer Accuracy
        4. Reasoning Path Accuracy (å¤šè·³é—®é¢˜)
        5. å¹³å‡å“åº”æ—¶é—´
        6. ä¸“å®¶åº“å‘½ä¸­ç‡
        
        åˆ†ç±»è¯„ä¼°ï¼š
        - å•è·³é—®é¢˜è¡¨ç°
        - å¤šè·³é—®é¢˜è¡¨ç°ï¼ˆæŒ‰è·³æ•°ç»†åˆ†ï¼‰
        - ä¸åŒé—®é¢˜ç±»å‹è¡¨ç°
        """
    
    def compare_with_baseline(self, baseline_results: Dict) -> ComparisonReport:
        """ä¸å¤§æ¨¡å‹åŸºçº¿å¯¹æ¯”"""
```

---

## æŠ€æœ¯å®ç°è¦ç‚¹

### 1. è‡ªåŠ¨ä¸“å®¶è¯†åˆ«ç®—æ³•

**æ–¹æ³•A: åŸºäºå®ä½“ç±»å‹èšç±»**
```python
def identify_by_entity_clustering(dataset):
    # 1. æå–æ‰€æœ‰å®ä½“åŠå…¶ç±»å‹
    entities = extract_all_entities(dataset)
    
    # 2. æ„å»ºå®ä½“-æ–‡æ¡£çŸ©é˜µ
    # 3. ä½¿ç”¨K-Meansæˆ–å±‚æ¬¡èšç±»
    # 4. æ¯ä¸ªç°‡å¯¹åº”ä¸€ä¸ªä¸“å®¶é¢†åŸŸ
    
    # ç¤ºä¾‹è¾“å‡ºï¼š
    # Expert 0: äººç‰©ç›¸å…³ï¼ˆæ¼”å‘˜ã€æ”¿æ²»å®¶ã€è¿åŠ¨å‘˜ï¼‰
    # Expert 1: åœ°ç†ç›¸å…³ï¼ˆåŸå¸‚ã€å›½å®¶ã€åœ°æ ‡ï¼‰
    # Expert 2: ç»„ç»‡ç›¸å…³ï¼ˆå…¬å¸ã€å¤§å­¦ã€æ”¿åºœæœºæ„ï¼‰
```

**æ–¹æ³•B: åŸºäºä¸»é¢˜æ¨¡å‹ï¼ˆLDAï¼‰**
```python
def identify_by_topic_modeling(dataset):
    # 1. å¯¹æ‰€æœ‰æ–‡æ¡£è¿›è¡ŒLDAä¸»é¢˜å»ºæ¨¡
    # 2. æ¯ä¸ªä¸»é¢˜å¯¹åº”ä¸€ä¸ªä¸“å®¶é¢†åŸŸ
    # 3. æ ¹æ®ä¸»é¢˜åˆ†å¸ƒåˆ†é…æ•°æ®
```

**æ–¹æ³•C: åŸºäºçŸ¥è¯†å›¾è°±ç¤¾åŒºæ£€æµ‹**
```python
def identify_by_graph_community(dataset):
    # 1. æ„å»ºå…¨å±€çŸ¥è¯†å›¾è°±
    # 2. ä½¿ç”¨Louvainæˆ–Label Propagationç®—æ³•æ£€æµ‹ç¤¾åŒº
    # 3. æ¯ä¸ªç¤¾åŒºå¯¹åº”ä¸€ä¸ªä¸“å®¶
```

### 2. å¤šè·³æ¨ç†å®ç°ç»†èŠ‚

**é“¾å¼æ¨ç†ä¼ªä»£ç **:
```python
def chain_reasoning(question, max_hops=5):
    context = ""
    current_query = question
    reasoning_path = []
    
    for hop in range(max_hops):
        # 1. è·¯ç”±åˆ°ä¸“å®¶
        experts = expert_router.route(current_query)
        
        # 2. æ£€ç´¢
        results = []
        for expert in experts:
            results.extend(expert.hybrid_retrieve(current_query))
        
        # 3. é‡æ’åº
        results = rerank(results, current_query)
        
        # 4. æ›´æ–°ä¸Šä¸‹æ–‡
        context += format_results(results)
        reasoning_path.append({
            'hop': hop + 1,
            'query': current_query,
            'results': results
        })
        
        # 5. åˆ¤æ–­æ˜¯å¦å¯ä»¥å›ç­”
        can_answer, answer = small_model.try_answer(question, context)
        if can_answer:
            return {
                'answer': answer,
                'reasoning_path': reasoning_path,
                'total_hops': hop + 1
            }
        
        # 6. ç”Ÿæˆä¸‹ä¸€è·³æŸ¥è¯¢
        current_query = small_model.generate_next_query(question, context)
    
    # è¶…è¿‡æœ€å¤§è·³æ•°ï¼Œå¼ºåˆ¶ç”Ÿæˆç­”æ¡ˆ
    return {
        'answer': small_model.final_answer(question, context),
        'reasoning_path': reasoning_path,
        'total_hops': max_hops,
        'complete': False
    }
```

### 3. ç¬¦å·æ¨ç†ç¤ºä¾‹

**çŸ¥è¯†å›¾è°±æŸ¥è¯¢**:
```python
# é—®é¢˜ï¼š"ç‰¹æ–¯æ‹‰CEOçš„æ¯æ ¡åœ¨å“ªä¸ªå·ï¼Ÿ"

# è½¬æ¢ä¸ºå›¾è°±æŸ¥è¯¢
query = {
    'pattern': [
        ('Tesla', 'CEO', '?person'),
        ('?person', 'educated_at', '?university'),
        ('?university', 'located_in', '?state')
    ],
    'return': ['?state']
}

# åœ¨å›¾è°±ä¸Šæ‰§è¡Œ
result = knowledge_graph.query(query)
# è¿”å›ï¼š[('Pennsylvania',)]

# ä¼˜åŠ¿ï¼š
# 1. æ¨ç†è·¯å¾„æ¸…æ™°
# 2. 100%å‡†ç¡®ï¼ˆå¦‚æœçŸ¥è¯†æ­£ç¡®ï¼‰
# 3. å¯è§£é‡Š
```

---

## ä¾èµ–å’Œç¯å¢ƒ

**requirements.txt**:
```
# æ ¸å¿ƒä¾èµ–
torch>=2.0.0
transformers>=4.30.0
sentence-transformers>=2.2.0

# å‘é‡æ£€ç´¢
faiss-cpu>=1.7.4  # or faiss-gpu
annoy>=1.17.0

# å›¾å¤„ç†
networkx>=3.0
python-louvain>=0.16

# NLPå·¥å…·
spacy>=3.5.0
nltk>=3.8

# æ•°æ®å¤„ç†
pandas>=2.0.0
numpy>=1.24.0

# ä¸»é¢˜æ¨¡å‹
gensim>=4.3.0
scikit-learn>=1.2.0

# é…ç½®ç®¡ç†
pyyaml>=6.0
hydra-core>=1.3.0

# å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
matplotlib>=3.7.0
seaborn>=0.12.0

# æµ‹è¯•
pytest>=7.3.0
```

---

## é¡¹ç›®ç»“æ„æ€»è§ˆ

```
NeuroSymbolic-Expert-QA/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.yaml
â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ knowledge_bases/
â”‚
â”œâ”€â”€ data/                   # æ•°æ®å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loader.py
â”‚   â”œâ”€â”€ preprocessor.py
â”‚   â””â”€â”€ models.py
â”‚
â”œâ”€â”€ kb_builder/             # çŸ¥è¯†åº“æ„å»º
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ expert_identifier.py
â”‚   â”œâ”€â”€ vector_builder.py
â”‚   â”œâ”€â”€ graph_builder.py
â”‚   â””â”€â”€ models.py
â”‚
â”œâ”€â”€ experts/                # ä¸“å®¶ç³»ç»Ÿ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_expert.py
â”‚   â”œâ”€â”€ expert_router.py
â”‚   â””â”€â”€ retriever.py
â”‚
â”œâ”€â”€ neuro_symbolic/         # ç¥ç»-ç¬¦å·è½¬æ¢
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ semantic_parser.py
â”‚   â”œâ”€â”€ query_generator.py
â”‚   â””â”€â”€ result_interpreter.py
â”‚
â”œâ”€â”€ qa_engine/              # é—®ç­”å¼•æ“
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ question_understanding.py
â”‚   â”œâ”€â”€ meta_reasoner.py
â”‚   â”œâ”€â”€ multi_hop_reasoner.py
â”‚   â””â”€â”€ answer_generator.py
â”‚
â”œâ”€â”€ pipeline/               # æµç¨‹ç¼–æ’
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ kb_build_pipeline.py
â”‚   â””â”€â”€ qa_pipeline.py
â”‚
â”œâ”€â”€ evaluation/             # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ utils/                  # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ graph_utils.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ config.py
â”‚
â””â”€â”€ tests/                  # æµ‹è¯•
    â”œâ”€â”€ test_kb_builder.py
    â”œâ”€â”€ test_experts.py
    â””â”€â”€ test_qa_engine.py
```

---

## ä½¿ç”¨ç¤ºä¾‹

### 1. æ„å»ºçŸ¥è¯†åº“
```bash
python main.py --mode build \
    --dataset ./data/raw/2wikimultihopqa \
    --config config.yaml
```

### 2. å›ç­”é—®é¢˜
```bash
python main.py --mode query \
    --question "Who is the CEO of Tesla's alma mater located state?"
```

### 3. è¯„ä¼°ç³»ç»Ÿ
```bash
python main.py --mode eval \
    --dataset ./data/raw/2wikimultihopqa/test.json
```

### 4. Python APIä½¿ç”¨
```python
from pipeline.qa_pipeline import QAPipeline

# åˆå§‹åŒ–
qa_system = QAPipeline(kb_path='./data/knowledge_bases')

# æé—®
answer = qa_system.answer("What is the capital of France?")

print(f"Answer: {answer.text}")
print(f"Confidence: {answer.confidence}")
print(f"Reasoning Path:")
for step in answer.reasoning_path:
    print(f"  {step}")
```

---

## åˆ›æ–°ç‚¹æ€»ç»“

1. **è‡ªåŠ¨ä¸“å®¶è¯†åˆ«**: ä»æ•°æ®é›†è‡ªåŠ¨è¯†åˆ«é¢†åŸŸï¼Œæ— éœ€äººå·¥æ ‡æ³¨
2. **ç¥ç»-ç¬¦å·æ··åˆ**: ç»“åˆå‘é‡æ£€ç´¢ï¼ˆçµæ´»ï¼‰å’Œå›¾è°±æ¨ç†ï¼ˆç²¾ç¡®ï¼‰
3. **åˆ†å¸ƒå¼æ¶æ„**: å¤šä¸ªä¸“å®¶åº“å¹¶è¡Œï¼Œå¯ç‹¬ç«‹ä¼˜åŒ–
4. **å¤šè·³æ¨ç†**: æ”¯æŒå¤æ‚çš„å¤šè·³é—®ç­”
5. **å¯è§£é‡Šæ€§**: æ¯ä¸ªç­”æ¡ˆéƒ½æœ‰æ¨ç†è·¯å¾„
6. **æ¨¡å—åŒ–è®¾è®¡**: ä½è€¦åˆé«˜å†…èšï¼Œæ˜“æ‰©å±•

---

## ä¸‹ä¸€æ­¥å¼€å‘å»ºè®®

**é˜¶æ®µ1: MVP (æœ€å°å¯è¡Œäº§å“)**
- å®ç°å•ä¸ªä¸“å®¶åº“
- å®ç°å•è·³é—®ç­”
- åœ¨å°è§„æ¨¡æ•°æ®é›†ä¸ŠéªŒè¯

**é˜¶æ®µ2: æ ¸å¿ƒåŠŸèƒ½**
- å®ç°å¤šä¸“å®¶è¯†åˆ«å’Œè·¯ç”±
- å®ç°å¤šè·³æ¨ç†
- å®Œæ•´çš„å‘é‡+å›¾è°±æ··åˆæ£€ç´¢

**é˜¶æ®µ3: ä¼˜åŒ–å’Œè¯„ä¼°**
- æ€§èƒ½ä¼˜åŒ–ï¼ˆæ£€ç´¢é€Ÿåº¦ã€å‡†ç¡®ç‡ï¼‰
- å®Œæ•´è¯„ä¼°ä½“ç³»
- ä¸åŸºçº¿å¯¹æ¯”

**é˜¶æ®µ4: æ‰©å±•åŠŸèƒ½**
- æ”¯æŒæ›´å¤šæ•°æ®é›†
- åœ¨çº¿å­¦ä¹ å’ŒçŸ¥è¯†æ›´æ–°
- Webç•Œé¢

---

## å¼€å‘ä¼˜å…ˆçº§å»ºè®®

### ç¬¬ä¸€æ‰¹ï¼ˆæ ¸å¿ƒåŸºç¡€ï¼‰
1. `data/models.py` - æ•°æ®æ¨¡å‹å®šä¹‰
2. `data/loader.py` - æ•°æ®åŠ è½½å™¨
3. `kb_builder/vector_builder.py` - å‘é‡ç´¢å¼•æ„å»º
4. `kb_builder/graph_builder.py` - å›¾è°±æ„å»º

### ç¬¬äºŒæ‰¹ï¼ˆä¸“å®¶ç³»ç»Ÿï¼‰
5. `kb_builder/expert_identifier.py` - ä¸“å®¶è¯†åˆ«
6. `experts/base_expert.py` - ä¸“å®¶åŸºç±»
7. `experts/expert_router.py` - è·¯ç”±å™¨
8. `pipeline/kb_build_pipeline.py` - çŸ¥è¯†åº“æ„å»ºæµç¨‹

### ç¬¬ä¸‰æ‰¹ï¼ˆé—®ç­”æ ¸å¿ƒï¼‰
9. `neuro_symbolic/semantic_parser.py` - è¯­ä¹‰è§£æ
10. `qa_engine/question_understanding.py` - é—®é¢˜ç†è§£
11. `qa_engine/multi_hop_reasoner.py` - å¤šè·³æ¨ç†
12. `qa_engine/answer_generator.py` - ç­”æ¡ˆç”Ÿæˆ

### ç¬¬å››æ‰¹ï¼ˆé›†æˆå’Œè¯„ä¼°ï¼‰
13. `pipeline/qa_pipeline.py` - é—®ç­”æµç¨‹
14. `evaluation/evaluator.py` - è¯„ä¼°å™¨
15. `main.py` - ä¸»ç¨‹åº
16. æµ‹è¯•å’Œæ–‡æ¡£

---

**æ–‡æ¡£å®Œæˆï¼å¯ä»¥åˆ†æ¨¡å—é€æ­¥è¾“å…¥ç»™Claude Codeè¿›è¡Œå¼€å‘ã€‚**
